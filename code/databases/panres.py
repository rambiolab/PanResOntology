import pandas as pd
from owlready2 import *
import subprocess
from loguru import logger
from collections import defaultdict

import sys
sys.path.append('..')
from functions import get_instance, clean_gene_name, get_or_create_instance
import re
import os

database2name = {
    'amrfinderplus': 'AMRFinderPlus',
    'argannot': 'ARGANNOT',
    'card_amr' :'CARD', 
    'csabapal': 'CsabaPal',
    'functional_amr': 'ResFinderFG',
    'megares': 'MegaRes',
    'metalres': 'MetalRes',
    'resfinder': 'ResFinder'
}

def discarded_genes(discarded_list: str, onto: Ontology):
    """Read a list of discarded genes from a file and return them as a list.

    Parameters
    ----------
    discarded_list : str
        Path to the file containing the list of discarded genes.

    Returns
    -------
    list
        A list of discarded gene names.
    """
    
    with open(discarded_list, 'r') as f:
        discarded = [l.strip().split('_v')[0].replace('>', '') for l in f.readlines()]

    for dg in discarded:
        onto.DiscardedPanGene(dg)
    
    return discarded

def add_panres_genes(file: str, uc_file: str, onto: Ontology, discarded: str, logger = logger):
    """Add PanRes genes to the ontology

    Parameters
    ----------
    file : str
        File containing metadata for the genes included in the first version of PanRes
    uc_file : str
        File containing the clustering information for the PanRes genes, as generated by usearch -cluster_fast
    onto : Ontology
        The Ontology to load the genes into
    discarded : str
        File with gene names that have been discarded from the PanRes database, e.g. because their sequence didnt contain correct start and stop codons
    logger : loguru.logger
        Logger object for logging messages.
    """

    # Load the metadata file (.tsv or .csv)

    # Clean up gene names and database names in the metadata
    panres_metadata = pd.read_csv(file, sep=',' if file.endswith('.csv') else '\t', skiprows=1)
    panres_metadata['userGeneName'] = panres_metadata['userGeneName'].str.replace("_v1.0.0", "", regex=False)
    panres_metadata['chosenSeq'] = panres_metadata['chosenSeq'].str.replace("_v1.0.0", "", regex=False)
    panres_metadata['database'] = panres_metadata['database'].str.replace("_genes", "")


    # Get list of discarded genes
    discarded_genes_list = discarded_genes(discarded, onto = onto)
    discarded_df = pd.DataFrame({'pan_gene': discarded_genes_list, 'status': 'discarded'})
    discarded_df = discarded_df.merge(
        panres_metadata.pivot_table(
            index='userGeneName',
            columns = 'database',
            values='fa_header',
            aggfunc=','.join
        ),
        left_on = 'pan_gene',
        right_index=True,
    )
    discarded_df.columns = discarded_df.columns.str.lower()#
    discarded_df = discarded_df.rename(columns = database2name)
    discarded_df.to_csv(os.path.join(os.path.dirname(discarded), 'panres_discarded_genes.csv'), index=False)

    # # Mark discarded genes from the metadata
    # panres_metadata['is_discarded'] = panres_metadata[panres_metadata['userGeneName'].isin(discarded_genes_list)]
    
    # Get a list of the unique gene names
    genes = panres_metadata['userGeneName'].unique().tolist()

    
    # Loop through each unique gene, add it to the ontology and its annotations
    for gene in set(genes):

        # Get annotation data for the correct gene
        m = panres_metadata.loc[panres_metadata['userGeneName'] == gene, ]
        
        # Make new PanGene instance
        new_gene = onto.PanGene(gene)

        if gene in discarded_genes_list:
            new_gene.is_discarded.append(onto.DiscardedPanGene(gene))
            logger.warning(f"PanRes: {gene} has been marked as discarded from the PanRes database.")

        # add the gene length if its consistent across all entries
        if m['gene_len'].nunique() == 1:
            new_gene.has_length.append(int(m['gene_len'].values[0]))
        else:
            logger.warning(f"PanRes: {gene} has multiple gene lengths associated.")
        
        # Loop through the annotation data for this gene
        for _, row in m.iterrows():
            # Map the full database name from the short name
            database_shortname = row['database']
            database_name = database2name[database_shortname.lower()]
            
            # Get the instance and link the original gene name to the database
            database_instance = get_instance(onto, database_name)
            new_gene.is_from_database.append(database_instance)

            # Clean and format the fasta header
            fasta_header = row['fa_header'].replace("~~~", "|").replace("'", "")
            gene_name = clean_gene_name(fasta_header, database_shortname.lower()).strip()

            # Add the cleaned gene name as an individual of the class OriginalGene
            original_gene_instance = onto.OriginalGene(gene_name)
                        
            # Track where the original gene name is from
            original_gene_instance.is_from_database.append(database_instance)
            original_gene_instance.original_fasta_header.append(fasta_header.strip() + '|' + database_name)

            # Annotate that the pan gene name is the same as the original gene name
            new_gene.same_as.append(original_gene_instance)
    
    # logger.info(f"Adding {len(genes)} PanRes genes to the ontology.")
    logger.success(f"Added PanRes genes (n={len(genes)}) to the ontology.")

    clusters = defaultdict(list)
    representatives = {}

    with open(uc_file, "r") as f:
        for line in f:
            cols = line.strip().split("\t")
            if len(cols) < 10:
                continue

            record_type = cols[0]
            cluster_no  = cols[1]
            query_label = cols[8]

            # Representative sequence = S
            if record_type == "S":
                representatives[cluster_no] = query_label
                clusters[cluster_no].append(query_label)

            # Member sequence = H
            elif record_type == "H":
                clusters[cluster_no].append(query_label)

    # Add PanGeneCluster instances and link genes to their clusters
    for cluster_no, members in clusters.items():
        
        rep = representatives.get(cluster_no)
        if rep is None:
            logger.warning(f"No representative found for cluster {cluster_no}")
            continue

        # Expect cluster centroid
        m = re.match(r"pan_(\d+)", rep)
        if not m:
            continue

        num = m.group(1)
        cluster_name = f"pan_cl{num}" 
        cl_inst = get_or_create_instance(onto=onto, cls=onto.PanGeneCluster, name=cluster_name)

        # Add cluster size
        cl_inst.has_members.append(str(len(members)))

        # Link each gene member to its cluster
        for mem in members:
            gene_inst = get_instance(onto = onto, name = mem)
            if gene_inst is not None:
                gene_inst.member_of.append(cl_inst)

    logger.success(f"Added {len(clusters)} PanGeneCluster instances.")


def add_panres_proteins(file: str, clstrs: str, struct_clstrs: str, onto: Ontology, logger):
    """Adds PanRes proteins and their clusters to the ontology.

    Parameters
    ----------
    file : str
        Path to the faa file containing PanRes protein sequences.
    clstrs : str
        Path to the clstr file containing PanRes protein clusters, as determined by CD-HIT.
    3dclstrs : str
        Path to the clustering.out file containing PanRes 3D protein clusters, as determined by clustering.py
    onto : Ontology
        The ontology to load the protein information into
    logger : loguru.logger
        Logger object for logging messages
    """

    # Grep all headers of the protein sequences and extract them
    #p = subprocess.run(f"grep '>' {file}", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    #protein_names = [l.split('_v1')[0].replace(">", "") for l in p.stdout.decode().split()]
    # protein2name = {
    #     l.strip(): l.split('_v1')[0].replace('>', '').replace('_', '').upper() for l in p.stdout.decode().split()
    # }
    # print(protein2name)

    # Get protein sequence lengths
    p = subprocess.run(f"seqkit faidx {file}",  shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    with open(file + '.fai', 'r') as f:
        # Read the fasta index file and extract protein names and lengths
        protein_lengths = {l.split()[0].split('_v1')[0]: int(l.split()[1]) for l in f.readlines() if l}
    
    # Loop through the protein names and add to the ontology
    for pan_name, protein_length in protein_lengths.items():
        protein_name = pan_name.replace('_', '').upper()
        protein_instance = get_or_create_instance(onto = onto, cls = onto.PanProtein, name=protein_name)
        
        # Add the protein length
        protein_instance.has_length.append(protein_length)

        # Get the corresponding gene instance and link the protein name to it
        gene_instance = get_instance(onto = onto, name = pan_name)
        if gene_instance is not None:
            gene_instance.translates_to.append(protein_instance)            

    # Log the successfull addition  of proteins
    logger.success("Added PanRes proteins to the ontology.")

    # Read the CD-HIT output file to extract cluster information
    p = re.compile(r">(pan\_\d+)")
    clusters = defaultdict(list)
    cluster_representative = None
    members = []
    with open(clstrs, 'r') as f:
        for l in f.readlines():
            l = l.strip()
            m = p.findall(l)

            # Check if the line indicates a new cluster
            if l.startswith('>Cluster'):
                if cluster_representative is not None:
                    clusters[cluster_representative] = members
                    members, cluster_representative = [], None
            # Else identify the cluster representative and it to the member list
            elif m and l.endswith('*'):
                cluster_representative = m[0]
                members.append(m[0])
            # Add members to the current cluster
            else:
                members.append(m[0])

    # Loop through each cluster and add it to the ontology
    for cl, cl_members in clusters.items():
        cl = cl.replace('pan_', 'PANCL')
        cluster_protein_instance = get_or_create_instance(onto = onto, cls = onto.PanProteinCluster, name=cl.replace('pan', 'Pan'))
        
        # Add how many members the cluster has
        cluster_protein_instance.has_members.append(str(len(cl_members)))

        # Link each protein member to its cluster representative
        for cl_member in cl_members:
            cl_member = cl_member.replace('pan_', 'PAN')
            #cl_instance = get_or_create_instance(onto = onto, cls = onto.PanProtein, name = cl_member.title())
            protein_instance = get_instance(onto = onto, name = cl_member)
            if protein_instance is not None:
                protein_instance.member_of.append(cluster_protein_instance)

    # Log the successful addition of protein clusters
    logger.success("Added PanRes 1D protein clusters to the ontology.")

    # Add protein structure class 
    for cl_rep, cl_members in clusters.items():
        # convert 'pan_123' to 'PAN123_struct'
        m = re.match(r'pan_(\d+)', cl_rep)
        if not m:
            continue
        num = m.group(1)
        struct_name = f"PAN{num}_struct"
        structure_instance = get_or_create_instance(onto=onto, cls=onto.PanStructure, name=struct_name)
        
        #link protein cluster to its structure
        cl = f"PANCL{num}"
        protein_cluster_instance = get_instance(onto=onto, name=cl)
        
        # Link each cluster to its structure
        protein_cluster_instance.folds_to.append(structure_instance)
    
    # Log the succesful addition of protein structures
    logger.success("Added PanRes protein structures to the ontology.")
    
    # Parse the clustering.out file to get 3D structure clusters
    struct_cl = defaultdict(list)

    with open(struct_clstrs, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            rep, member = line.split("\t")
            rep = rep.split("_v")[0]       # strip version: pan_123_v1 → pan_123
            member = member.split("_v")[0]
            struct_cl[rep].append(member)

    logger.success("Parsed PanRes 3D structure clusters.")
    

    for rep, struct_members in struct_cl.items():
        m = re.match(r"pan_(\d+)", rep)
        if not m:
            continue
        num = m.group(1)

        # Create structure cluster
        struct_cluster_name = f"PANCL{num}_struct"
        struct_cluster_instance = get_or_create_instance(onto=onto,cls=onto.PanStructureCluster,name=struct_cluster_name)
        
        # Link number of members to each cluster
        struct_cluster_instance.has_members.append(str(len(struct_members)))

        # Link each structure member to its cluster
        for mem in struct_members:
            mm = re.match(r"pan_(\d+)", mem)
            if not mm:
                continue
            mnum = mm.group(1)
            mem_struct_name = f"PAN{mnum}_struct"

            member_struct_instance = get_or_create_instance(onto=onto, cls=onto.PanStructure, name=mem_struct_name)

            # link structure → structure cluster
            member_struct_instance.member_of.append(struct_cluster_instance)

    logger.success("Added PanRes 3D structure clusters to the ontology.")


def add_panres_ecoli_homologs(onto: Ontology, infile: str, logger):
    """
    Add is_ecoli_homolog annotation to PanProtein instances.
    File format (TSV with header):

    PanProtein    is_ecoli_homolog
    pan_5_v1.0.1_identical    1
    """

    with open(infile, "r") as f:
        header = f.readline().strip().split("\t")
        if header[0] != "PanProtein" or header[1] != "is_ecoli_homolog":
            logger.error("Incorrect file format: expected 'PanProtein' and 'is_ecoli_homolog' columns.")
            return

        added = 0
        missing = 0

        for line in f:
            line = line.strip()
            if not line:
                continue
            fields = line.split("\t")
            if len(fields) < 2:
                continue
            raw_name = fields[0]               
            flag     = fields[1].strip()
            #conver to bool 
            is_homolog = (flag == "1")

            # pan_1 to PAN1
            pan_base = raw_name.split("_v")[0]
            protein_name = pan_base.replace("_", "").upper()

            # Retrieve protein instance
            protein_inst = get_instance(onto, protein_name)
            protein_inst.is_ecoli_homolog.append(is_homolog)
            added += 1

    logger.success(f"Annotated is_ecoli_homolog for {added} PanProtein instances.")

